{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1166ead8-daf6-4202-998b-522181130b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.transforms import Bbox\n",
    "from scipy.optimize import fmin_tnc, newton\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150f2090-d58b-4eb6-a055-0a74944d5aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure text parameters\n",
    "plt.rc('font', size=20)\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath,amssymb,bm,bbm,lmodern}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157bcfeb-b6f9-4022-ad9a-214a5937c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure parameters\n",
    "name_mapping = {\n",
    "    'method_1': 'Sample Mean',\n",
    "    'method_2': 'Affine Mean',\n",
    "    'method_3': 'Affine Weighted',\n",
    "    'method_4': 'Maximum Likelihood'\n",
    "}\n",
    "colours = {\n",
    "    'method_1': \"black\",\n",
    "    'method_2': \"red\",\n",
    "    'method_3': \"gold\",\n",
    "    'method_4': \"aqua\",\n",
    "  }\n",
    "markers = {\n",
    "    'method_1': 'x',\n",
    "    'method_2': '^',\n",
    "    'method_3': 'v',\n",
    "    'method_4': 'o'\n",
    "  }\n",
    "styles = {\n",
    "    'method_1': '-',\n",
    "    'method_2': \":\",\n",
    "    'method_3': '--',\n",
    "    'method_4': '-.'\n",
    "  }\n",
    "linewidths = {\n",
    "    \"method_1\": 2, \n",
    "    \"method_2\": 4.5, \n",
    "    \"method_3\": 3.5, \n",
    "    \"method_4\": 3.5\n",
    "}\n",
    "\n",
    "num_points_plotted = 50  # Too many points leads to jitter\n",
    "alpha = 0.4  # Opacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093c875-2047-4626-9e28-07b4bf28b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000  # Num runs\n",
    "n = 1000000  # Num ratings per run\n",
    "p = 0.4  # True relevance\n",
    "\n",
    "# True lambda distribution parameters. Replace if running weak bandwagon scenario.\n",
    "a = 0.1\n",
    "b = 0.95\n",
    "graph_name = \"strong_bw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47365d07-8093-4afb-8549-14e8c817176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting helper variables\n",
    "x_values = np.arange(1, n + 1)\n",
    "plot_idx = (np.unique(np.geomspace(1,n,num_points_plotted).astype(int))-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f65b6e2-6ec5-4b6e-b1fd-7f30ad93389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True lambda distribution: lambda_i = a + (1-a)*b**(i-1)\n",
    "lambdas = a + (1 - a)*b**np.arange(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4e7ef3-3b65-4b41-b35a-19b84550c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data by iterating over Equation 4\n",
    "R = np.zeros((N,n))  # Keep track of individual ratings\n",
    "M = np.zeros((N,n))  # Keep track of sample mean\n",
    "ri = np.random.rand(N) < p  # First rating sampled from Bernoulli(p)\n",
    "R[:,0] = ri\n",
    "M[:,0] = ri\n",
    "m = ri\n",
    "\n",
    "# Iterate over timesteps (all runs in parallel)\n",
    "for i in tqdm(range(1,n)):\n",
    "    pri = lambdas[i]*p + (1 - lambdas[i])*m  # Calculate P(r_n=1|\\bar{p}_{n-1})\n",
    "    ri = np.random.rand(N) < pri  # Sample new rating\n",
    "    m = (m*i + ri)/(i + 1)  # Update sample mean\n",
    "    R[:,i] = ri  # Record the new rating\n",
    "    M[:,i] = m  # Record the new sample mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f040f9c9-d600-40e6-bbc0-a858c9f76e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Only run this cell if using misestimated bandwagon values for estimators\n",
    "a_hat, b_hat = 0.3305, 0.9185\n",
    "lambdas_hat = a_hat + (1 - a_hat)*b_hat**np.arange(n)\n",
    "lambdas = lambdas_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b50314c-15e8-4cba-ac20-ff9bab5d8a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample mean as it was prior to the rating at the same index\n",
    "M_prev = np.concatenate((np.ones((N,1)), M[:,:-1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69df933-7f03-4b82-bc5b-d0df73e2a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine estimators for each step\n",
    "r_hat = (R - (1 - lambdas)*M_prev)/lambdas  # Equation 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9febf8-54a3-413e-8467-e04e0a16edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine mean estimator\n",
    "p_hat = np.cumsum(r_hat, axis=1)/np.arange(1, n+1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed421ec-c97c-4502-bd80-a453092987f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine weighted estimator\n",
    "p_hat_2 = np.cumsum(lambdas*r_hat, axis=1)/np.cumsum(lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de5fcd8-4148-4b70-b5cd-68f51d6bde78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Run this cell if training and saving the outputs for MLE (next cell) in a separate run.\n",
    "del r_hat\n",
    "del p_hat, p_hat_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef82848-cc6f-47ad-bd28-9f0a4da73981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Maximum Likelihood - can get memory intensive\n",
    "def f(p_current, r, m_shifted, lambdas):\n",
    "    \"\"\"Calculate the derivative of the log likelihood wrt. true relevance p estimate for a bandwagon process using\n",
    "    m <= n first ratings.\n",
    "    \n",
    "    Args:\n",
    "        p_current (np.array): Initial/current guess for the true relevance w/ shape (N, ).\n",
    "        r (np.array): Observed ratings at each timestep w/ shape (N, m).\n",
    "        m_shifted (np.array): Observed sample means before a given timestep w/ shape (N, m).\n",
    "        lambdas (np.array): Estimated (or true) lambda values w/ shape (m, )\n",
    "    \"\"\"\n",
    "    p_current = np.clip(p_current, 1e-8, 1-1e-8)  # Assume p \\in (0, 1)\n",
    "    denom = lambdas*p_current[:,None] + (1 - lambdas)*m_shifted\n",
    "    dl_dp = np.sum(lambdas*((r/denom) - (1 - r)/(1 - denom)), axis=-1)\n",
    "    return dl_dp\n",
    "\n",
    "x0 = np.ones(N)*0.5  # Initial guess\n",
    "ml = np.zeros((N,n))  # Initialize output\n",
    "bounds = (1e-8, 1 - 1e-8)  # Assume p \\in (0, 1)\n",
    "\n",
    "# Break down along N if memory an issue\n",
    "num_splits = 20\n",
    "split_size = int(np.ceil(N/num_splits))\n",
    "maxiter = 200\n",
    "\n",
    "for j in range(num_splits):\n",
    "    split_low, split_high = j*split_size, (j+1)*split_size\n",
    "    if j + 1 == num_splits:\n",
    "        split_high = N\n",
    "    \n",
    "    # Only calculate MLE for num_interactions that get plotted.\n",
    "    for i in tqdm(plot_idx):\n",
    "        pred = np.clip(\n",
    "            newton(\n",
    "                f, \n",
    "                x0[split_low:split_high], \n",
    "                args=(R[split_low:split_high,:i+1], M_prev[split_low:split_high,:i+1], lambdas[:i+1]), \n",
    "                maxiter=maxiter\n",
    "            ),\n",
    "            *bounds)\n",
    "        ml[split_low:split_high,i] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5162fe-edcf-43ba-8cfb-d76dab9d4b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Comment out models if any should be excluded due to memory limitations\n",
    "include_all = {\n",
    "    \"method_1\": M\n",
    "}\n",
    "include_specific = {\n",
    "    \"method_2\": p_hat,\n",
    "    \"method_3\": p_hat_2,\n",
    "    \"method_4\": ml\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa59e26-ba2b-476d-a240-247bb7048dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    **{k: v.mean(axis=0) for k, v in include_all.items()},\n",
    "    **{k: v.mean(axis=0) for k, v in include_specific.items()}\n",
    "}\n",
    "\n",
    "ci = {\n",
    "    **{k:(np.percentile(v, 5, axis=0), np.percentile(v,100-5,axis=0)) for k, v in include_all.items()},\n",
    "    **{k:(np.percentile(v, 5, axis=0), np.percentile(v,100-5,axis=0)) for k, v in include_specific.items()}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d9226-6444-40a3-9d5a-98e47fbe8bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Run this cell if saving or loading current predictions\n",
    "data_root = \"/your/path/to/store(d)/data\"\n",
    "data_path = os.path.join(data_root, graph_name)\n",
    "os.makedirs(data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4317d2e7-8465-4d29-b140-9b039ad4dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Run this cell to save current predictions to disk\n",
    "for k, a in data.items():\n",
    "    array_path = os.path.join(data_path, f\"{k}_mean.npy\")\n",
    "    np.save(array_path, a)\n",
    "\n",
    "for k,a in ci.items():\n",
    "    array_path = os.path.join(data_path, f\"{k}_ci.npy\")\n",
    "    np.save(array_path, np.stack(ci[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a825eb-eb54-4b50-ba33-8c24a7899797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Run this cell to load data/predictions from disk\n",
    "include_all = [\"method_1\"]\n",
    "include_specific = [\"method_2\", \"method_3\", \"method_4\"]\n",
    "\n",
    "data = {}\n",
    "ci = {}\n",
    "\n",
    "for k in include_all + include_specific:\n",
    "    mean_path = os.path.join(data_path, f\"{k}_mean.npy\")\n",
    "    ci_path = os.path.join(data_path, f\"{k}_ci.npy\")\n",
    "    data[k] = np.load(mean_path)\n",
    "    ci[k] = tuple(x[0] for x in np.split(np.load(ci_path), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b52bb-10c0-40ec-9f90-7a39cf60385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_info = {}\n",
    "for k in data:\n",
    "    legend_info[k] = {\n",
    "        'linestyle': styles[k],\n",
    "        'color': colours[k],\n",
    "        'markersize': 12,\n",
    "        'fillstyle': 'none',\n",
    "        'label': name_mapping[k],\n",
    "        'linewidth': linewidths[k]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc0cecf-c85c-4bd5-a381-285105ce6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over models (except sample mean, which is included in every figure).\n",
    "# Create a separate figure for every model\n",
    "for k in include_specific:\n",
    "    y = data[k]\n",
    "    fig = plt.figure(figsize=(7.38/1.5, 1.25*2), linewidth=0.5)\n",
    "    fig.tight_layout()\n",
    "    plt.ioff()\n",
    "    plt.xscale('log')\n",
    "    plt.gca().yaxis.set_ticks_position('both')\n",
    "    plt.gca().xaxis.set_ticks_position('both')\n",
    "    plt.xlim(1, n)\n",
    "    plt.xticks(10**np.arange(np.log10(n)+1))\n",
    "    plt.ylim(0, 1.)\n",
    "    \n",
    "    # Plot the confidence interval for the current model\n",
    "    y_min, y_max = ci[k]\n",
    "    plt.fill_between(\n",
    "        x_values[plot_idx], y_min[plot_idx], y_max[plot_idx],\n",
    "        alpha=alpha if k != \"method_4\" else alpha-0.1,\n",
    "        color=legend_info[k][\"color\"],\n",
    "        zorder=3\n",
    "    )\n",
    "\n",
    "    # Bolden the confidence interval lines\n",
    "    plt.plot(x_values[plot_idx], y_min[plot_idx], color=legend_info[k][\"color\"], alpha=0.3)\n",
    "    plt.plot(x_values[plot_idx], y_max[plot_idx], color=legend_info[k][\"color\"], alpha=0.3)\n",
    "\n",
    "    # Plot the mean for the current model\n",
    "    plt.plot(x_values[plot_idx], y[plot_idx], zorder=2, **legend_info[k])\n",
    "    \n",
    "    # Plot the mean and the confidence interval of the sample mean in the background\n",
    "    for _k in include_all:\n",
    "        _y = data[_k]\n",
    "        _y_min, _y_max = ci[_k]\n",
    "        plt.fill_between(\n",
    "            x_values[plot_idx], _y_min[plot_idx], _y_max[plot_idx],\n",
    "            alpha=alpha,\n",
    "            color=legend_info[_k][\"color\"],\n",
    "            zorder=2\n",
    "        )\n",
    "        plt.plot(x_values[plot_idx], _y[plot_idx], zorder=1, **legend_info[_k])\n",
    "    \n",
    "    plt.savefig('./%s_%s.pdf' % (graph_name, name_mapping[k].replace(' ', '_')), bbox_inches='tight', pad_inches=0)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5977fc-17b6-4f18-9e1f-fed11ed45cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the legend as a separate figure\n",
    "figlegend = plt.figure(figsize=(0.5,0.5))\n",
    "ncol = len(data)\n",
    "figlegend.legend(handles=[mlines.Line2D([], [], **l) for l in legend_info.values()],\n",
    "               fontsize=18,\n",
    "               loc='center',\n",
    "               ncol=ncol,\n",
    "               frameon=False,\n",
    "               borderaxespad=0,\n",
    "               borderpad=0,\n",
    "               labelspacing=0.2,\n",
    "               columnspacing=1.)\n",
    "figlegend.savefig(f'./{graph_name}_legend.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b5e99-c8b1-4e2b-98fb-4619819997dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project Bandwagon Conda 3.9",
   "language": "python",
   "name": "proj_bandwagon_conda-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
